{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 20 01:06:58 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 40%   42C    P0    66W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 36%   45C    P0    41W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "|128%   89C    P2   236W / 280W |  18236MiB / 24220MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 51%   73C    P2   302W / 280W |  18182MiB / 24220MiB |     91%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "cuda available True\n",
      "gpu_count 2\n",
      "torch version 1.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkeewonshin\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install wandb --upgrade --user\n",
    "# !pip install monai tensorboard==1.15 --user\n",
    "\n",
    "# About GPU setting\n",
    "!nvidia-smi\n",
    "gpus= \"0,1\"\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus;\n",
    "\n",
    "import torch\n",
    "gpu_count = torch.cuda.device_count()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('cuda available',torch.cuda.is_available())\n",
    "print('gpu_count',gpu_count)\n",
    "print('torch version',torch.__version__)\n",
    "\n",
    "# Ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# set Logger\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# img_list = glob.glob('../Brain_Normal_trainset/label/*.nii.gz')\n",
    "# for idx in range(len(img_list)):\n",
    "#     src = img_list[idx]\n",
    "#     dst = '../Brain_Normal_trainset/label/'+img_list[idx].split('/')[-1].split('.')[0]+'_normal.nii.gz'\n",
    "# #     print(src)\n",
    "#     shutil.move(src,dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lt3pdawcASI"
   },
   "source": [
    "# Step 1ï¸âƒ£. Define the Sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czI6CWeCeTmJ"
   },
   "source": [
    "### ðŸ“ƒ Sweep mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "G0jKcJON9ID2"
   },
   "outputs": [],
   "source": [
    "sweep_config = {'method': 'random'} # 'grid'\n",
    "metric = {'name': 'val_loss', 'goal': 'minimize' }\n",
    "\n",
    "sweep_config['metric'] = metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czI6CWeCeTmJ"
   },
   "source": [
    "### ðŸ“ƒ Name the hyper`parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_fzZawC4cr2o"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "path_data = '../AMC/'\n",
    "path_statedict = '0SegResNetbest.pth'\n",
    "\n",
    "parameters_dict = {\n",
    "    'epochs': {'values': [4]},\n",
    "#     'learning_rate': {'distribution': 'uniform','min': 1e-5, 'max': 1e-2},\n",
    "#     'batch_size': {'distribution': 'q_log_uniform', 'q': 1, 'min': math.log(2),'max': math.log(4)},\n",
    "    'learning_rate': {'values': [1e-3]},\n",
    "    'batch_size': {'values': [4*gpu_count]},\n",
    "    'optimizer': {'values': ['adam']},\n",
    "    'lossfn': { 'values': ['DiceCE']}, #'CrossEntropy','DiceFocal'\n",
    "    'model': {'values':['segresnet']}, #'unet','ahnet','hiresnet'\n",
    "    'temperature' : {'values': [0.2]},\n",
    "    'transform' : {'values': [0]},\n",
    "    'fold' : {'values': [0]}, # [0,1,2,3,4]    \n",
    "    'in_channels' : {'values': [1]}, \n",
    "    'out_channels' : {'values': [2]},\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6v7-Q7jdNEU"
   },
   "source": [
    "# Step 2ï¸âƒ£. Initialize the Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cc-06shTB2Vz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: zwqthc45\n",
      "Sweep URL: https://wandb.ai/keewonshin/pytorch-sweeps-demo/sweeps/zwqthc45\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"pytorch-sweeps-demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlkILpCrddRp"
   },
   "source": [
    "# Step 3ï¸âƒ£. Run the Sweep agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3cPz_DmdSJy"
   },
   "source": [
    "### ðŸ’» Define Your Training Procedure\n",
    "\n",
    "Before we can actually execute the sweep,\n",
    "we need to define the training procedure that uses those values.\n",
    "\n",
    "In the functions below, we define a simple fully-connected neural network in PyTorch, and add the following `wandb` tools to log model metrics, visualize performance and output and track our experiments:\n",
    "* [**`wandb.init()`**](https://docs.wandb.com/library/init) â€“ Initialize a new W&B Run. Each Run is a single execution of the training function.\n",
    "* [**`wandb.config`**](https://docs.wandb.com/library/config) â€“ Save all your hyperparameters in a configuration object so they can be logged. Read more about how to use `wandb.config` [here](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-config/Configs_in_W%26B.ipynb).\n",
    "* [**`wandb.log()`**](https://docs.wandb.com/library/log) â€“ log model behavior to W&B. Here, we just log the performance; see [this Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Log_(Almost)_Anything_with_W%26B_Media.ipynb) for all the other rich media that can be logged with `wandb.log`.\n",
    "\n",
    "For more details on instrumenting W&B with PyTorch, see [this Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.3.0+109.g8f80ac5\n",
      "Numpy version: 1.19.4\n",
      "Pytorch version: 1.7.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 8f80ac521b00d75c247a21e6a2aae87408ef4790\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.2\n",
      "Nibabel version: 3.2.0\n",
      "scikit-image version: 0.17.2\n",
      "Pillow version: 8.0.1\n",
      "Tensorboard version: 2.3.0\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.8.1\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.51.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.7.3\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import tqdm\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import *\n",
    "import monai\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, list_data_collate\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import *\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import *\n",
    "from monai.transforms import *\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import Dataset, CacheDataset, DataLoader, create_test_image_3d\n",
    "from monai.engines import EnsembleEvaluator, SupervisedEvaluator, SupervisedTrainer\n",
    "from monai.handlers import MeanDice, StatsHandler, ValidationHandler\n",
    "from monai.inferers import SimpleInferer, SlidingWindowInferer\n",
    "\n",
    "set_determinism(seed=0)\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)\n",
    "# patch_size = (64,64,16)\n",
    "patch_size = (256,256,16)\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadNiftid(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),        \n",
    "        \n",
    "        #spacing\n",
    "#         Spacingd(keys=[\"image\", \"label\"], pixdim=(.67, .67), mode=(\"bilinear\", \"nearest\")),\n",
    "#         Spacingd(keys=[\"image\", \"label\"], pixdim=(.67, .67, 3.0), mode=(\"nearest\", \"nearest\")),\n",
    "\n",
    "        # windowing\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=40-140/2, a_max=40+140/2, b_min=0.0, b_max=1.0, clip=True),\n",
    "#         ScaleIntensityRanged(keys=[\"label\"], a_min=0, a_max=2, b_min=0, b_max=2, clip=True),\n",
    "        \n",
    "        # intensity & smoothing & sharpen\n",
    "        RandGaussianNoised(keys=[\"image\"],mean=0.0, std=0.05,prob=0.3),\n",
    "        RandAdjustContrastd(keys=[\"image\"],gamma=(0.5, 4.5), prob=0.3),\n",
    "        RandShiftIntensityd(keys=[\"image\"],offsets= (-0.1, 0.1), prob=0.3),\n",
    "        RandScaleIntensityd(keys=[\"image\"],factors= (0, 0.1), prob=0.3),\n",
    "        RandGaussianSmoothd(keys=[\"image\"],sigma_x=(0.25, 1.0), sigma_y=(0.25, 1.0), sigma_z=(0.25, 1.0), prob=0.3),\n",
    "        RandHistogramShiftd(keys=[\"image\"],num_control_points=(10,20), prob=0.3),\n",
    "#         RandGaussianSharpend(keys=[\"image\"],sigma1_x=(0.1, 1.0), sigma1_y=(0.1, 1.0), sigma1_z=(0.1, 1.0), sigma2_x=0.5, sigma2_y=0.5, sigma2_z=0.5, alpha=(10.0, 30.0), prob=.5),\n",
    "        \n",
    "        # spatial\n",
    "        RandFlipd(keys=[\"image\",\"label\"], spatial_axis=[0,1], prob=0.3),        \n",
    "        RandRotate90d(keys=[\"image\", \"label\"], spatial_axes=[0,1],prob=0.3),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=patch_size,\n",
    "            pos=1,\n",
    "            neg=1.5,\n",
    "            num_samples=4,\n",
    "        ),\n",
    "#         Rand3DElasticd(\n",
    "#                 keys=[\"image\", \"label\"],\n",
    "#                 mode=(\"bilinear\", \"nearest\"),\n",
    "#                 prob=0.3,\n",
    "#                 sigma_range=(7, 9),\n",
    "#                 magnitude_range=(100, 150),\n",
    "#                 spatial_size=patch_size,\n",
    "#                 rotate_range=(0, 0, np.pi / 2),\n",
    "#                 shear_range=(0.1, 0.1, 0),\n",
    "#                 scale_range=(0.1, 0.1, 0),\n",
    "#                 padding_mode=\"border\",\n",
    "#                 device=device,\n",
    "#                 ),\n",
    "        \n",
    "        CastToTyped(keys=[\"image\", \"label\"], dtype=(np.float32, np.uint8)),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadNiftid(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),            \n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=40-140/2, a_max=40+140/2, b_min=0.0, b_max=1.0, clip=True),\n",
    "#         ScaleIntensityRanged(keys=[\"image\"], a_min=30-500/2, a_max=30+500/2, b_min=0.0, b_max=1.0, clip=True),\n",
    "#         ScaleIntensityRanged(keys=[\"label\"], a_min=0, a_max=2, b_min=0, b_max=2, clip=True),\n",
    "        \n",
    "        CastToTyped(keys=[\"image\", \"label\"], dtype=(np.float32, np.uint8)),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loader = DataLoader(val_ds, batch_size=1, num_workers=2)\n",
    "# test_ds = Dataset(data=test_files, transform=val_transforms)\n",
    "# test_loader = DataLoader(test_ds, batch_size=1, num_workers=2)\n",
    "# test1_ds = Dataset(data=test1_files, transform=val_transforms)\n",
    "# test1_loader = DataLoader(test1_ds, batch_size=1, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r4VjKui20N3j"
   },
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    # Initialize a new wandb run\n",
    "\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        config = wandb.config\n",
    "        experiment = \"model:{}_optimizer:{}_transform:{}_fold:{}\".format(config.model, config.optimizer, config.transform, config.fold)\n",
    "        print('Experiment:',experiment)\n",
    "\n",
    "        train_loader, val_loader = build_dataset(path_data, config.fold, config.batch_size)\n",
    "        model = build_model(config.model,path_statedict,config.in_channels,config.out_channels)\n",
    "        optimizer = build_optimizer(model, config.optimizer, config.learning_rate)\n",
    "        lossfn = build_loss(config.lossfn)\n",
    "        \n",
    "        val_losses = list()\n",
    "        for epoch in range(config.epochs):\n",
    "            \n",
    "            train_loss, train_metric = train_epoch(model, train_loader, optimizer, lossfn)\n",
    "            val_loss, val_metric = val_epoch(model, val_loader, lossfn)\n",
    "            \n",
    "            val_losses.append(val_loss)    \n",
    "            if epoch >= 3 and val_loss == np.min(val_losses):\n",
    "                if torch.cuda.device_count() > 1:\n",
    "                    torch.save(model.module.state_dict(),experiment+'best.pth')\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), str(fold)+modelname+'best.pth')\n",
    "                print('saved new best val_loss of the model')                \n",
    "            elif epoch >= 3 and val_losses != np.min(val_losses):\n",
    "                config.learning_rate = config.learning_rate * .95\n",
    "                optimizer = build_optimizer(model, config.optimizer, config.learning_rate)\n",
    "\n",
    "            wandb.log({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_metric\": train_metric,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_metric\": val_metric,\n",
    "                \"epoch\": epoch,\n",
    "            })           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(path_data, fold, batch_size):\n",
    "    \n",
    "    x_train = sorted(glob.glob(path_data+'imageTr/*.nii.gz'))\n",
    "    y_train = sorted(glob.glob(path_data+'labelTr/*.nii.gz'))\n",
    "    \n",
    "    folds = 5\n",
    "    x_train_split = monai.data.partition_dataset(data=x_train,num_partitions=folds,seed=0,shuffle=True)\n",
    "    y_train_split = monai.data.partition_dataset(data=y_train,num_partitions=folds,seed=0,shuffle=True)\n",
    "\n",
    "    train_files,val_files = list(), list()\n",
    "    for idx in range(folds):\n",
    "        if idx == fold:\n",
    "            val_files.extend([{\"image\": img, \"label\": seg} for img, seg in zip(x_train_split[idx],y_train_split[idx])])\n",
    "        else:\n",
    "            train_files.extend([{\"image\": img, \"label\": seg} for img, seg in zip(x_train_split[idx],y_train_split[idx])])\n",
    "\n",
    "#     test_files = [{\"image\": img, \"label\": seg} for img, seg in zip(x_test,y_test)]\n",
    "    \n",
    "    train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "    val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size*gpu_count, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def build_optimizer(model, optimizer, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "def build_model(model,path_statedict=None,in_channels=1,out_channels=2):\n",
    "    if model == \"unet\":\n",
    "        model = UNet(dimensions=3, in_channels=1, out_channels=2, channels=(32, 64, 128, 256, 512), strides=(2, 2, 2, 2), num_res_units=3, norm=Norm.INSTANCE)\n",
    "    elif model == \"segresnet\":\n",
    "        model = SegResNet(spatial_dims=3, in_channels=1, out_channels=2, init_filters=8)\n",
    "    elif model == \"ahnet\":\n",
    "        model = AHNet(spatial_dims=3, in_channels=1, out_channels=2, pretrained=True)\n",
    "    elif model == \"hiresnet\":\n",
    "        model = HighResNet(spatial_dims=3, in_channels=1, out_channels=2)\n",
    "        \n",
    "    if path_statedict is not None:\n",
    "        try:\n",
    "            model_w = torch.load(path_statedict)\n",
    "            model.load_state_dict(model_w, strict=False)\n",
    "            print('loading weights is successfully done')\n",
    "        except:\n",
    "            print('loading weights is failed')\n",
    "            \n",
    "    # do not change here\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model= model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_loss(loss = \"CrossEntropy\"):\n",
    "    if loss == \"CrossEntropy\":\n",
    "        lossfn = CrossEntropyLoss()\n",
    "    elif loss == \"DiceCE\":\n",
    "        lossfn = DiceCELoss()\n",
    "    elif loss == \"DiceFocal\":\n",
    "        lossfn = DiceFocalLoss()\n",
    "    return lossfn\n",
    "\n",
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.loss = nn.CrossEntropyLoss(weight=torch.tensor([.1,.2,.4,.4]))\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # CrossEntropyLoss target needs to have shape (B, D, H, W)\n",
    "        # Target from pipeline has shape (B, C, D, H, W)\n",
    "        y_true = torch.squeeze(y_true, dim=1).long()\n",
    "        return self.loss(y_pred, y_true)\n",
    "\n",
    "class DiceCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dice = GeneralizedDiceLoss(to_onehot_y=True)\n",
    "        self.cross_entropy = CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        dice = self.dice(y_pred, y_true)\n",
    "        cross_entropy = self.cross_entropy(y_pred, y_true)\n",
    "        return dice + cross_entropy\n",
    "    \n",
    "class DiceFocalLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dice = GeneralizedDiceLoss(to_onehot_y=True)\n",
    "        self.focal = FocalLoss(gamma=2)\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        dice = self.dice(y_pred, y_true)\n",
    "        focal = self.focal(y_pred, y_true)\n",
    "        return dice + focal\n",
    "\n",
    "def softmax_T(inputs,T=0.1):\n",
    "    '''\n",
    "    input should be torch and B*C*H...\n",
    "    '''\n",
    "#     T = config.temperature\n",
    "    return torch.softmax(inputs/T,1)\n",
    "\n",
    "def train_epoch(model, loader, optimizer, lossfn):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_metric = 0\n",
    "\n",
    "    for batch_data in tqdm.tqdm(loader, desc='train'):\n",
    "        x, y = batch_data['image'].to(device), batch_data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # âž¡ Forward pass        \n",
    "        y_hat = softmax_T(model(x))\n",
    "        loss = lossfn(y_hat, y)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # â¬… Backward pass + weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_hat = torch.argmax(y_hat,1)\n",
    "        metric = f1_score(y.detach().cpu().numpy().flatten(), y_hat.detach().cpu().numpy().flatten())\n",
    "        epoch_metric += metric\n",
    "\n",
    "        wandb.log({\"batch_train_loss\": loss.item()})\n",
    "        wandb.log({\"batch_train_metric\": metric})\n",
    "        \n",
    "    return epoch_loss / len(loader), epoch_metric / len(loader)\n",
    "\n",
    "def val_epoch(model, loader, lossfn):\n",
    "\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_metric = 0\n",
    "\n",
    "    for batch_data in tqdm.tqdm(loader, desc='valid'):\n",
    "        x, y = batch_data['image'].to(device), batch_data['label'].to(device)\n",
    "       \n",
    "        sw_batch_size = 2\n",
    "        y_hat = softmax_T(sliding_window_inference(x, patch_size, sw_batch_size, model))\n",
    "\n",
    "        loss = lossfn(y_hat, y)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        y_hat = torch.argmax(y_hat,1)\n",
    "        metric = f1_score(y.detach().cpu().numpy().flatten(), y_hat.detach().cpu().numpy().flatten())\n",
    "        epoch_metric += metric\n",
    "\n",
    "        wandb.log({\"batch_val_loss\": loss.item()})\n",
    "        wandb.log({\"batch_val_metric\": metric})\n",
    "        \n",
    "    return epoch_loss / len(loader), epoch_metric / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(sweep_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHpan13W6UZD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1ovru8dj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tin_channels: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlossfn: DiceCE\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: segresnet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tout_channels: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemperature: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransform: 0\n",
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">deep-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/keewonshin/pytorch-sweeps-demo\" target=\"_blank\">https://wandb.ai/keewonshin/pytorch-sweeps-demo</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/keewonshin/pytorch-sweeps-demo/sweeps/zwqthc45\" target=\"_blank\">https://wandb.ai/keewonshin/pytorch-sweeps-demo/sweeps/zwqthc45</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/keewonshin/pytorch-sweeps-demo/runs/1ovru8dj\" target=\"_blank\">https://wandb.ai/keewonshin/pytorch-sweeps-demo/runs/1ovru8dj</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/Brain_Hemo/Code/wandb/run-20201220_010707-1ovru8dj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: model:segresnet_optimizer:adam_transform:0_fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/129 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weight is failed\n",
      "Let's use 2 GPUs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  26%|â–ˆâ–ˆâ–Œ       | 33/129 [29:25<1:21:59, 51.25s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop. See /workspace/Brain_Hemo/Code/wandb/run-20201220_010707-1ovru8dj/logs/debug-internal.log for full traceback.\n",
      "train:  26%|â–ˆâ–ˆâ–‹       | 34/129 [30:15<1:20:42, 50.98s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:36.318010, resuming normal operation.\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [1:51:47<00:00, 52.00s/it]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 515/515 [1:03:41<00:00,  7.42s/it]\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [1:53:06<00:00, 52.61s/it]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 515/515 [1:03:20<00:00,  7.38s/it]\n",
      "train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 80/129 [1:16:03<47:28, 58.13s/it]  \u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop. See /workspace/Brain_Hemo/Code/wandb/run-20201220_010707-1ovru8dj/logs/debug-internal.log for full traceback.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:36.170288, resuming normal operation.\n",
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [1:59:19<00:00, 55.50s/it]\n",
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 515/515 [1:04:51<00:00,  7.56s/it]\n",
      "train:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/129 [45:56<1:10:15, 52.69s/it]"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = sorted(glob.glob(path_data+'imageTs/*.nii.gz'))\n",
    "y_test = sorted(glob.glob(path_data+'labelTs/*.nii.gz'))\n",
    "test_files = [{\"image\": img, \"label\": seg} for img, seg in zip(x_test,y_test)]\n",
    "test_ds = Dataset(data=test_files, transform=val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=2)\n",
    "\n",
    "model = build_model('segresnet','0SegResNetbest.pth',1,2)\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, val_data in enumerate(test_loader):\n",
    "            image = val_data[\"image\"] \n",
    "            label = val_data[\"label\"]\n",
    "            fname_image = val_data[\"image_meta_dict\"]['filename_or_obj'][0]\n",
    "            fname_label = val_data[\"label_meta_dict\"]['filename_or_obj'][0]\n",
    "\n",
    "            fname_image = 'Output/image_'+fname_image.split('/')[-1]\n",
    "            fname_label = 'Output/label_'+fname_label.split('/')[-1]\n",
    "            fname_pred = 'Output/pred_'+fname_image.split('/')[-1]\n",
    "            affine = val_data[\"image_meta_dict\"]['affine'][0]\n",
    "            original_affine = val_data[\"image_meta_dict\"]['original_affine'][0]\n",
    "            spatial_shape = val_data[\"image_meta_dict\"]['spatial_shape'][0]\n",
    "\n",
    "            roi_size = patch_size\n",
    "            sw_batch_size = 4\n",
    "            outputs = sliding_window_inference(val_data[\"image\"].to(device), roi_size, sw_batch_size, model, 0.5, 'gaussian')\n",
    "            outputs = torch.softmax(outputs, dim=1)\n",
    "    #         outputs = torch.argmax(outputs, dim=1).unsqueeze(1)\n",
    "            outputs = outputs[:,1].unsqueeze(1)\n",
    "            print(label.shape,torch.unique(label),torch.unique(outputs))\n",
    "\n",
    "            # for color visualization\n",
    "            label_ = label.clone()\n",
    "            outputs_ = outputs.clone()\n",
    "            for idx in range(2):\n",
    "                label_[0,0,0,idx,:] = idx\n",
    "                outputs_[0,0,0,idx,:] = idx\n",
    "\n",
    "            for idx in range(label.shape[-1]):\n",
    "    #             if len(torch.unique(label[...,idx]))>=2:\n",
    "                    plt.figure(\"check\", (18, 6))\n",
    "                    plt.subplot(1, 3, 1)\n",
    "                    plt.title(f\"{fname_image} {idx}\")\n",
    "                    plt.imshow(image[0, 0, :, :, idx], cmap=\"gray\")\n",
    "                    plt.subplot(1, 3, 2)\n",
    "                    plt.title(f\"label {i}\")\n",
    "                    plt.imshow(image[0, 0, :, :, idx], cmap=\"gray\")\n",
    "                    plt.imshow(label_[0, 0, :, :, idx], alpha=0.5)\n",
    "                    plt.subplot(1, 3, 3)\n",
    "                    plt.title(f\"output {i}\")\n",
    "                    plt.imshow(image[0, 0, :, :, idx], cmap=\"gray\")\n",
    "                    plt.imshow(outputs_.detach().cpu()[0, 0,:, :,idx], alpha=0.5)\n",
    "                    plt.show()                  \n",
    "\n",
    "    #         monai.data.write_nifti(data=image.cpu().detach().numpy().squeeze(),\n",
    "    #                                file_name=fname_image,\n",
    "    #                                resample=True,\n",
    "    #                                affine=affine,\n",
    "    #                                target_affine=original_affine,\n",
    "    #                                output_spatial_shape=spatial_shape)\n",
    "\n",
    "    #         monai.data.write_nifti(data=label.cpu().detach().numpy().squeeze(),\n",
    "    #                                file_name=fname_label,\n",
    "    #                                resample=True,\n",
    "    #                                affine=affine,\n",
    "    #                                target_affine=original_affine,\n",
    "    #                                output_spatial_shape=spatial_shape)\n",
    "\n",
    "    #         monai.data.write_nifti(data=outputs.cpu().detach().numpy().squeeze(),\n",
    "    #                                file_name=fname_pred,\n",
    "    #                                resample=True,\n",
    "    #                                affine=affine,\n",
    "    #                                target_affine=original_affine,\n",
    "    #                                output_spatial_shape=spatial_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Organizing Hyperparameter Sweeps in PyTorch with W&B",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
